{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IUbmSxMTkm1"
   },
   "outputs": [],
   "source": [
    "#to load preprocessod video to memory\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "video_files =  glob.glob('AllData/dfdc_train_part_00/*.mp4')\n",
    "random.shuffle(video_files)\n",
    "frame_count = []\n",
    "for video_file in video_files[:int(len(video_files)/100)]: #filter out files that are not enough to train the model\n",
    "  cap = cv2.VideoCapture(video_file) #read video file\n",
    "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<100): #if frame count<100 then delete\n",
    "    video_files.remove(video_file)\n",
    "    continue\n",
    "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print(\"frames are \" , frame_count)\n",
    "print(\"Total no of video: \" , len(frame_count))\n",
    "print('Average frame per video:',np.mean(frame_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kH67eZKTrv8"
   },
   "outputs": [],
   "source": [
    "# load the video name and labels from csv\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "class video_dataset(Dataset):\n",
    "    def __init__(self,video_names,labels,sequence_length = 60,transform = None):\n",
    "        self.video_names = video_names#constructor\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.count = sequence_length\n",
    "    def __len__(self):\n",
    "        return len(self.video_names)#no of videos\n",
    "    def __getitem__(self,idx):\n",
    "        video_path = self.video_names[idx]\n",
    "        frames = []\n",
    "        a = int(100/self.count) #dividing the video in groups of no of frames selected\n",
    "        first_frame = np.random.randint(0,a) #starting with any random group\n",
    "        temp_video = video_path.split('\\\\')[-1]\n",
    "#         print(temp_video)\n",
    "        label = self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
    "        if(label == 0):\n",
    "          label = 0\n",
    "        if(label == 1):\n",
    "          label = 1\n",
    "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
    "          frames.append(self.transform(frame))\n",
    "          if(len(frames) == self.count):\n",
    "            break\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames[:self.count]\n",
    "        #print(\"length:\" , len(frames), \"label\",label)\n",
    "        return frames,label\n",
    "    def frame_extract(self,path):\n",
    "      vidObj = cv2.VideoCapture(path)\n",
    "      success = 1\n",
    "      while success:\n",
    "          success, image = vidObj.read()\n",
    "          if success:\n",
    "              yield image\n",
    "#plot the image\n",
    "def im_plot(tensor):\n",
    "    image = tensor.cpu().numpy().transpose(1,2,0)\n",
    "    b,g,r = cv2.split(image)\n",
    "    image = cv2.merge((r,g,b))\n",
    "    image = image*[0.22803, 0.22145, 0.216989] +  [0.43216, 0.394666, 0.37645]\n",
    "    image = image*255.0\n",
    "    plt.imshow(image.astype(int))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8N1A2LpITtSG"
   },
   "outputs": [],
   "source": [
    "#count the number of fake and real videos\n",
    "def number_of_real_and_fake_videos(data_list):\n",
    "  header_list = [\"file\",\"label\"]\n",
    "  lab = pd.read_csv('AllData/dfdc_train_part_00/metadata0.csv',names=header_list,skiprows=1)\n",
    "\n",
    "\n",
    "# convert the column from string to int\n",
    "  lab['label']=lab['label'].astype(int)\n",
    "  realvideos = []\n",
    "  fakevideos = []\n",
    "# check the new datatypes of each column\n",
    "        #print(temp_video)\n",
    "  fake = 0\n",
    "  real = 0\n",
    "  for i in data_list:\n",
    "    temp_video = i.split('\\\\')[-1]\n",
    "    # print(temp_video,lab.loc[lab[\"file\"] == temp_video])\n",
    "    label = lab.iloc[(lab.loc[lab[\"file\"] == temp_video].index.values[0]),1]\n",
    "    if(label == 0):\n",
    "      fake=fake+1\n",
    "      fakevideos.append(i)\n",
    "    if(label == 1):\n",
    "      real=real+1\n",
    "      realvideos.append(i)\n",
    "  return real,fake, realvideos, fakevideos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEsoHRUiTvWW"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "header_list = [\"file\",\"label\"]\n",
    "labels = pd.read_csv('AllData/dfdc_train_part_00/metadata0.csv',names=header_list,skiprows=1)\n",
    "labels['label']=labels['label'].astype(int)\n",
    "#print(labels)\n",
    "# print(video_files)\n",
    "train_videos = video_files[:int(0.8*len(video_files))]\n",
    "valid_videos = video_files[int(0.8*len(video_files)):]\n",
    "# print(\"train : \" , len(train_videos))\n",
    "# print(\"test : \" , len(valid_videos))\n",
    "# train_videos,valid_videos = train_test_split(data,test_size = 0.2)\n",
    "# print(train_videos)\n",
    "# print(number_of_real_and_fake_videos(train_videos))\n",
    "# print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0], \" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
    "# print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(valid_videos)[0], \" Fake:\",number_of_real_and_fake_videos(valid_videos)[1])\n",
    "\n",
    "reall = number_of_real_and_fake_videos(train_videos)[2]\n",
    "reall = reall+number_of_real_and_fake_videos(valid_videos)[2]\n",
    "fakee = number_of_real_and_fake_videos(train_videos)[3]\n",
    "fakee = fakee+number_of_real_and_fake_videos(valid_videos)[3]\n",
    "oversampling_factor = len(fakee) / len(reall)\n",
    "balanced_real_videos = [video for video in reall for _ in range(int(oversampling_factor))]\n",
    "balanced_video_paths = balanced_real_videos + fakee\n",
    "# balanced_real_videos = random.sample(reall * oversampling_factor, k=len(fakee))\n",
    "# balanced_video_paths = balanced_real_videos + fakee\n",
    "random.shuffle(balanced_video_paths)\n",
    "print(len(balanced_video_paths))\n",
    "train_videos = balanced_video_paths[:int(0.8*len(balanced_video_paths))]\n",
    "valid_videos = balanced_video_paths[int(0.8*len(balanced_video_paths)):]\n",
    "print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0], \" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
    "print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(valid_videos)[0], \" Fake:\",number_of_real_and_fake_videos(valid_videos)[1])\n",
    "# print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(balanced_video_paths)[0], \" Fake:\",number_of_real_and_fake_videos(balanced_video_paths)[1])\n",
    "\n",
    "\n",
    "im_size = 112 #size of input image to model\n",
    "#for normalization so that the mean is zero and unit variance to get more accuracy\n",
    "mean = [0.485, 0.456, 0.406] # mean-values of RGB\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "train_data = video_dataset(train_videos,labels,sequence_length=60,transform = train_transforms)\n",
    "#print(train_data)\n",
    "val_data = video_dataset(valid_videos,labels,sequence_length=60,transform = train_transforms)\n",
    "train_loader = DataLoader(train_data,batch_size = 1,shuffle = True,num_workers = 0)# class in pytorch that helps with batch processing\n",
    "valid_loader = DataLoader(val_data,batch_size = 1,shuffle = True,num_workers = 0)\n",
    "image,label = train_data[0]\n",
    "# print((train_data))\n",
    "im_plot(image[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dvzr3gxTxKc"
   },
   "outputs": [],
   "source": [
    "#Model with feature visualization\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        model = models.VGG16_32x4d(pretrained = True) #pre trained ResNet using torchvision\n",
    "        self.model = nn.Sequential(*list(model.children())[:-2])#last 2 layers removed because those are used for object detection and adding layers\n",
    "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional) #using LSTM layer that is bidirectional\n",
    "        self.relu = nn.LeakyReLU() #leaky ReLU overcomes the the problem of dying ReLU which happens when the neuron isnt able to learn anymore\n",
    "        self.dp = nn.Dropout(0.7) #dropout is implemented to avoid overfitting by dropping out neutrons\n",
    "        self.linear1 = nn.Linear(2048,num_classes) #adding a linear layer to produce output\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1) # reduce the dimension to a single value to send it to LSTM\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)# reduces the dimension to 1X1\n",
    "        x = x.view(batch_size,seq_length,2048)\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GKvFXCQT0Ji"
   },
   "outputs": [],
   "source": [
    "model = Model(2).cuda()\n",
    "a,b = model(torch.from_numpy(np.empty((1,20,3,224,224))).type(torch.cuda.FloatTensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Os_hStlDT1uS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    print(data_loader)\n",
    "    t = []\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            print(targets)\n",
    "            # targets = torch.as_tensor(targets)\n",
    "            targets = targets.type(torch.cuda.LongTensor)\n",
    "            inputs = inputs.cuda()\n",
    "        _,outputs = model(inputs)\n",
    "        loss  = criterion(outputs,targets.type(torch.cuda.LongTensor))\n",
    "        acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        accuracies.update(acc, inputs.size(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%]\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    num_epochs,\n",
    "                    i,\n",
    "                    len(data_loader),\n",
    "                    losses.avg,\n",
    "                    accuracies.avg))\n",
    "\n",
    "    torch.save(model.state_dict(),'content/checkpoint.pt')\n",
    "    return losses.avg,accuracies.avg\n",
    "def test(epoch,model, data_loader ,criterion):\n",
    "    print('Testing')\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    pred = []\n",
    "    true = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(data_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                targets = targets.cuda().type(torch.cuda.FloatTensor)\n",
    "                inputs = inputs.cuda()\n",
    "            _,outputs = model(inputs)\n",
    "            loss = torch.mean(criterion(outputs, targets.type(torch.cuda.LongTensor)))\n",
    "            acc = calculate_accuracy(outputs,targets.type(torch.cuda.LongTensor))\n",
    "            _,p = torch.max(outputs,1)\n",
    "            true += (targets.type(torch.cuda.LongTensor)).detach().cpu().numpy().reshape(len(targets)).tolist()\n",
    "            pred += p.detach().cpu().numpy().reshape(len(p)).tolist()\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            accuracies.update(acc, inputs.size(0))\n",
    "            sys.stdout.write(\n",
    "                    \"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%]\"\n",
    "                    % (\n",
    "                        i,\n",
    "                        len(data_loader),\n",
    "                        losses.avg,\n",
    "                        accuracies.avg\n",
    "                        )\n",
    "                    )\n",
    "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
    "    return true,pred,losses.avg,accuracies.avg\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    _, pred = outputs.topk(1, 1, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1))\n",
    "    n_correct_elems = correct.float().sum().item()\n",
    "    return 100* n_correct_elems / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQeRdXYlT35T"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "#Output confusion matrix\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('True positive = ', cm[0][0])\n",
    "    print('False positive = ', cm[0][1])\n",
    "    print('False negative = ', cm[1][0])\n",
    "    print('True negative = ', cm[1][1])\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['Real', 'Fake'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    plt.show()\n",
    "    # calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkOYIixIT5dO"
   },
   "outputs": [],
   "source": [
    "def plot_loss(train_loss_avg,test_loss_avg,num_epochs):\n",
    "  loss_train = train_loss_avg\n",
    "  loss_val = test_loss_avg\n",
    "  print(num_epochs)\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "  plt.title('Training and Validation loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "def plot_accuracy(train_accuracy,test_accuracy,num_epochs):\n",
    "  loss_train = train_accuracy\n",
    "  loss_val = test_accuracy\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "  plt.title('Training and Validation accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "il8QaAyQT7L6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "#learning rate\n",
    "lr = 1e-2#0.001\n",
    "#number of epochs\n",
    "num_epochs = 3\n",
    "pin_memory=True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= lr,weight_decay = 1e-2)\n",
    "\n",
    "#class_weights = torch.from_numpy(np.asarray([1,15])).type(torch.FloatTensor).cuda()\n",
    "#criterion = nn.CrossEntropyLoss(weight = class_weights).cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "train_loss_avg =[]\n",
    "train_accuracy = []\n",
    "test_loss_avg = []\n",
    "test_accuracy = []\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    l, acc = train_epoch(epoch,num_epochs,train_loader,model,criterion,optimizer)\n",
    "    train_loss_avg.append(l)\n",
    "    train_accuracy.append(acc)\n",
    "    true,pred,tl,t_acc = test(epoch,model,valid_loader,criterion)\n",
    "    test_loss_avg.append(tl)\n",
    "    test_accuracy.append(t_acc)\n",
    "plot_loss(train_loss_avg,test_loss_avg,len(train_loss_avg))\n",
    "plot_accuracy(train_accuracy,test_accuracy,len(train_accuracy))\n",
    "print(confusion_matrix(true,pred))\n",
    "print_confusion_matrix(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:mlenv]",
   "language": "python",
   "name": "conda-env-mlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
